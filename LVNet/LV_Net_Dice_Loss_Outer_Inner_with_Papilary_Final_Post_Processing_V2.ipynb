{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Testing Data for computation of Jaccard Index\n",
      "0\n",
      "10\n",
      "20\n",
      "30\n",
      "40\n",
      "50\n",
      "60\n",
      "70\n",
      "80\n",
      "90\n",
      "100\n",
      "110\n",
      "120\n",
      "130\n",
      "140\n",
      "150\n",
      "160\n",
      "170\n",
      "180\n",
      "190\n",
      "200\n",
      "210\n",
      "220\n",
      "230\n",
      "240\n",
      "250\n",
      "260\n",
      "270\n",
      "280\n",
      "290\n",
      "300\n",
      "310\n",
      "320\n",
      "330\n",
      "340\n",
      "0.8683130749704316\n",
      "0.9848000592301783\n",
      "0.9024017795154323\n",
      "0.9601278918528418\n",
      "0.8233202517222761\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import scipy.io as sio\n",
    "import cv2\n",
    "import numpy as np\n",
    "from sklearn.metrics import jaccard_similarity_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "\n",
    "\n",
    "name_save_directory = \"LV_Net_Dice_Loss_Inner_with_Papilary_V2\"\n",
    "results = \"_Results\"\n",
    "parent_directory = \"/tank/data/navchetan/Lars_Annotated_Datasets/Results/\"\n",
    "saveFolder = os.path.join(parent_directory,name_save_directory)\n",
    "name_save_results_directory = name_save_directory+results\n",
    "path_segment_inner = os.path.join(saveFolder,name_save_results_directory)\n",
    "\n",
    "name_save_directory = \"LV_Net_Dice_Loss_Outer_V2\"\n",
    "results = \"_Results\"\n",
    "parent_directory = \"/tank/data/navchetan/Lars_Annotated_Datasets/Results/\"\n",
    "saveFolder = os.path.join(parent_directory,name_save_directory)\n",
    "name_save_results_directory = name_save_directory+results\n",
    "path_segment_outer = os.path.join(saveFolder,name_save_results_directory)\n",
    "\n",
    "name_save_directory = \"LV_Net_Dice_Loss_with_papilary_V2\"\n",
    "results = \"_Results\"\n",
    "parent_directory = \"/tank/data/navchetan/Lars_Annotated_Datasets/Results/\"\n",
    "saveFolder = os.path.join(parent_directory,name_save_directory)\n",
    "name_save_results_directory = name_save_directory+results\n",
    "path_segment_normal = os.path.join(saveFolder,name_save_results_directory)\n",
    "\n",
    "name_save_directory = \"LV_Net_Dice_Loss_Outer_Inner_with_Papilary_Final_Post_Processing_V2\"\n",
    "saving_metrics = 'Metrics_LV_Net_Dice_Loss_Outer_Inner_with_Papilary_Final_Post_Processing_V2.csv'\n",
    "\n",
    "results = \"_Results\"\n",
    "images = \"_Joint_Images\"\n",
    "parent_directory = \"/tank/data/navchetan/Lars_Annotated_Datasets/Results/\"\n",
    "saveFolder = os.path.join(parent_directory,name_save_directory)\n",
    "# os.mkdir(saveFolder)\n",
    "\n",
    "name_save_results_directory = name_save_directory+results\n",
    "path_results_save = os.path.join(saveFolder,name_save_results_directory)\n",
    "# os.mkdir(path_results_save)\n",
    "\n",
    "name_save_images_directory = name_save_directory+images\n",
    "path_images_save = os.path.join(saveFolder,name_save_images_directory)\n",
    "# os.mkdir(path_images_save)\n",
    "\n",
    "\n",
    "cols = ['sensitivity','specificity','accuracy','dice_score','Jaccard']\n",
    "df = pd.DataFrame(columns=cols)\n",
    "ratio=['Ratio']\n",
    "dfr=pd.DataFrame(columns=ratio)\n",
    "path_testing_ground_truth =\"/tank/data/navchetan/Lars_Annotated_Datasets/Testing_Output_With_Papillary\"\n",
    "\n",
    "N_TESTING_SAMPLES = 342\n",
    "print('Loading Testing Data for computation of Jaccard Index')\n",
    "sensitivity_t = 0\n",
    "specificity_t = 0\n",
    "accuracy_t = 0\n",
    "dice_score_t = 0\n",
    "Jaccard_t = 0\n",
    "countoutin = 0\n",
    "for i in range(N_TESTING_SAMPLES):\n",
    "    if(i%10 == 0):\n",
    "        print(i)\n",
    "    os.chdir(path_segment_outer)    \n",
    "    pathr = 'Segment_Output'+str(i+1).zfill(5)+'.mat'\n",
    "    x = sio.loadmat(pathr)\n",
    "    Segment_model = x['S']\n",
    "    Segment_model1 = Segment_model*255;\n",
    "    retval1, Segment_model_threshold = cv2.threshold(Segment_model1,100,255,cv2.THRESH_BINARY)\n",
    "    Segment_model_threshold_out = Segment_model_threshold/255.0\n",
    "    \n",
    "    os.chdir(path_segment_inner)    \n",
    "    pathr = 'Segment_Output'+str(i+1).zfill(5)+'.mat'\n",
    "    x = sio.loadmat(pathr)\n",
    "    Segment_model = x['S']\n",
    "    Segment_model1 = Segment_model*255;\n",
    "    retval1, Segment_model_threshold = cv2.threshold(Segment_model1,100,255,cv2.THRESH_BINARY)\n",
    "    Segment_model_threshold_in = Segment_model_threshold/255.0\n",
    "    \n",
    "    Segment_model_threshold1=Segment_model_threshold_out-Segment_model_threshold_in\n",
    "    \n",
    "    for k in range(256):\n",
    "        for l in range(256):\n",
    "            if Segment_model_threshold1[k,l]<0:\n",
    "                Segment_model_threshold1[k,l]=0\n",
    "                \n",
    "    \n",
    "    os.chdir(path_segment_normal)    \n",
    "    pathr = 'Segment_Output'+str(i+1).zfill(5)+'.mat'\n",
    "    x = sio.loadmat(pathr)\n",
    "    Segment_model = x['S']\n",
    "    Segment_model1 = Segment_model*255;\n",
    "    retval1, Segment_model_threshold = cv2.threshold(Segment_model1,100,255,cv2.THRESH_BINARY)\n",
    "    Segment_outin = Segment_model_threshold/255.0\n",
    "    \n",
    "#     kernel=cv2.getStructuringElement(cv2.MORPH_ELLIPSE,(7,7)) \n",
    "#     Segment_outin= cv2.morphologyEx(Segment_outin, cv2.MORPH_CLOSE, kernel)\n",
    "#     Segment_outin = cv2.morphologyEx(Segment_outin, cv2.MORPH_OPEN, kernel)\n",
    "#     Segment_outin= cv2.morphologyEx(Segment_outin, cv2.MORPH_CLOSE, kernel)\n",
    "#     Segment_outin = cv2.morphologyEx(Segment_outin, cv2.MORPH_OPEN, kernel)\n",
    "    \n",
    "    for m in range(256):\n",
    "        for n in range(256):\n",
    "            if Segment_model_threshold1[m,n]==1 and Segment_outin[m,n]==0:\n",
    "                Segment_model_threshold1[m,n]=1\n",
    "            elif Segment_model_threshold1[m,n]==0 and Segment_outin[m,n]==1:\n",
    "                Segment_model_threshold1[m,n]=1\n",
    "            elif Segment_model_threshold1[m,n]==0 and Segment_outin[m,n]==0:\n",
    "                Segment_model_threshold1[m,n]=0\n",
    "# chnaging form here\n",
    "#     for m in range(256):\n",
    "#         for n in range(256):\n",
    "#             if Segment_model_threshold1[m,n]==1 and Segment_model_threshold_out[m,n]==0:\n",
    "#                 Segment_model_threshold1[m,n]=0\n",
    "#             elif Segment_model_threshold1[m,n]==0 and Segment_model_threshold_out[m,n]==1:\n",
    "#                 Segment_model_threshold1[m,n]=0\n",
    "#             elif Segment_model_threshold1[m,n]==0 and Segment_model_threshold_out[m,n]==0:\n",
    "#                 Segment_model_threshold1[m,n]=0\n",
    "#             elif Segment_model_threshold1[m,n]==1 and Segment_model_threshold_out[m,n]==1:\n",
    "#                 Segment_model_threshold1[m,n]=1\n",
    "# upto here\n",
    "    kernel=cv2.getStructuringElement(cv2.MORPH_ELLIPSE,(7,7))            \n",
    "    Segment_model_threshold1= cv2.morphologyEx(Segment_model_threshold1, cv2.MORPH_CLOSE, kernel)\n",
    "    Segment_model_threshold1 = cv2.morphologyEx(Segment_model_threshold1, cv2.MORPH_OPEN, kernel)\n",
    "    Segment_model_threshold1= cv2.morphologyEx(Segment_model_threshold1, cv2.MORPH_CLOSE, kernel)\n",
    "    Segment_model_threshold1 = cv2.morphologyEx(Segment_model_threshold1, cv2.MORPH_OPEN, kernel)    \n",
    "    \n",
    "    os.chdir(path_results_save)\n",
    "    S = Segment_model_threshold1\n",
    "    countoutin = countoutin + 1\n",
    "    fsave = 'Segment_Output'+str(countoutin).zfill(5)+'.mat'\n",
    "    sio.savemat(fsave, {'S':S})\n",
    "            \n",
    "    os.chdir(path_testing_ground_truth)\n",
    "    path_t = 'Segment'+str(i+1).zfill(5)+'.mat'\n",
    "    y = sio.loadmat(path_t)\n",
    "    ground_truth_testing  = y['S']\n",
    "    ground_truth1 = ground_truth_testing*255;\n",
    "    retval2, ground_truth_testing_threshold = cv2.threshold(ground_truth1,0,255,cv2.THRESH_BINARY)\n",
    "    ground_truth_testing_threshold1 = ground_truth_testing_threshold/255.0\n",
    "    \n",
    "    mcm = confusion_matrix(np.ndarray.flatten(Segment_model_threshold1),np.ndarray.flatten(ground_truth_testing_threshold1))\n",
    "    tn = mcm[0, 0]\n",
    "    fp = mcm[0, 1]\n",
    "    fn = mcm[1, 0]\n",
    "    tp = mcm[1, 1]\n",
    "    \n",
    "    sensitivity = tp / (tp + fn)\n",
    "    specificity = tn / (tn + fp)\n",
    "    accuracy = (tp + tn) / (tp + tn + fn + fp)\n",
    "    dice_score = 2*tp / (2*tp + fp + fn)\n",
    "    Jaccard = dice_score / (2-dice_score)\n",
    "    \n",
    "    sensitivity_t = sensitivity_t + sensitivity\n",
    "    specificity_t = specificity_t + specificity\n",
    "    accuracy_t = accuracy_t + accuracy\n",
    "    dice_score_t = dice_score_t + dice_score\n",
    "    Jaccard_t = Jaccard_t + Jaccard\n",
    "    \n",
    "    \n",
    "    df = df.append(pd.Series([sensitivity,specificity,accuracy,dice_score,Jaccard],index=df.columns), ignore_index=True)\n",
    "\n",
    "os.chdir(saveFolder)\n",
    "df.to_csv(saving_metrics,index=False)\n",
    "#dfr.to_csv('Ratio.csv')\n",
    "print(sensitivity_t/N_TESTING_SAMPLES)\n",
    "print(specificity_t/N_TESTING_SAMPLES)\n",
    "print(dice_score_t/N_TESTING_SAMPLES)\n",
    "print(accuracy_t/N_TESTING_SAMPLES)\n",
    "print(Jaccard_t/N_TESTING_SAMPLES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.05215239732944125\n",
      "0.010436276211473335\n",
      "0.027999463533178958\n",
      "0.013294337815073737\n",
      "0.04549394700138018\n"
     ]
    }
   ],
   "source": [
    "print(np.std(df.sensitivity))\n",
    "print(np.std(df.specificity))\n",
    "print(np.std(df.dice_score))\n",
    "print(np.std(df.accuracy))\n",
    "print(np.std(df.Jaccard))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "10\n",
      "20\n",
      "30\n",
      "40\n",
      "50\n",
      "60\n",
      "70\n",
      "80\n",
      "90\n",
      "100\n",
      "110\n",
      "120\n",
      "130\n",
      "140\n",
      "150\n",
      "160\n",
      "170\n",
      "180\n",
      "190\n",
      "200\n",
      "210\n",
      "220\n",
      "230\n",
      "240\n",
      "250\n",
      "260\n",
      "270\n",
      "280\n",
      "290\n",
      "300\n",
      "310\n",
      "320\n",
      "330\n",
      "340\n",
      "0\n",
      "10\n",
      "20\n",
      "30\n",
      "40\n",
      "50\n",
      "60\n",
      "70\n",
      "80\n",
      "90\n",
      "100\n",
      "110\n",
      "120\n",
      "130\n",
      "140\n",
      "150\n",
      "160\n",
      "170\n",
      "180\n",
      "190\n",
      "200\n",
      "210\n",
      "220\n",
      "230\n",
      "240\n",
      "250\n",
      "260\n",
      "270\n",
      "280\n",
      "290\n",
      "300\n",
      "310\n",
      "320\n",
      "330\n",
      "340\n",
      "0\n",
      "10\n",
      "20\n",
      "30\n",
      "40\n",
      "50\n",
      "60\n",
      "70\n",
      "80\n",
      "90\n",
      "100\n",
      "110\n",
      "120\n",
      "130\n",
      "140\n",
      "150\n",
      "160\n",
      "170\n",
      "180\n",
      "190\n",
      "200\n",
      "210\n",
      "220\n",
      "230\n",
      "240\n",
      "250\n",
      "260\n",
      "270\n",
      "280\n",
      "290\n",
      "300\n",
      "310\n",
      "320\n",
      "330\n",
      "340\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "60\n",
      "61\n",
      "62\n",
      "63\n",
      "64\n",
      "65\n",
      "66\n",
      "67\n",
      "68\n",
      "69\n",
      "70\n",
      "71\n",
      "72\n",
      "73\n",
      "74\n",
      "75\n",
      "76\n",
      "77\n",
      "78\n",
      "79\n",
      "80\n",
      "81\n",
      "82\n",
      "83\n",
      "84\n",
      "85\n",
      "86\n",
      "87\n",
      "88\n",
      "89\n",
      "90\n",
      "91\n",
      "92\n",
      "93\n",
      "94\n",
      "95\n",
      "96\n",
      "97\n",
      "98\n",
      "99\n",
      "100\n",
      "101\n",
      "102\n",
      "103\n",
      "104\n",
      "105\n",
      "106\n",
      "107\n",
      "108\n",
      "109\n",
      "110\n",
      "111\n",
      "112\n",
      "113\n",
      "114\n",
      "115\n",
      "116\n",
      "117\n",
      "118\n",
      "119\n",
      "120\n",
      "121\n",
      "122\n",
      "123\n",
      "124\n",
      "125\n",
      "126\n",
      "127\n",
      "128\n",
      "129\n",
      "130\n",
      "131\n",
      "132\n",
      "133\n",
      "134\n",
      "135\n",
      "136\n",
      "137\n",
      "138\n",
      "139\n",
      "140\n",
      "141\n",
      "142\n",
      "143\n",
      "144\n",
      "145\n",
      "146\n",
      "147\n",
      "148\n",
      "149\n",
      "150\n",
      "151\n",
      "152\n",
      "153\n",
      "154\n",
      "155\n",
      "156\n",
      "157\n",
      "158\n",
      "159\n",
      "160\n",
      "161\n",
      "162\n",
      "163\n",
      "164\n",
      "165\n",
      "166\n",
      "167\n",
      "168\n",
      "169\n",
      "170\n",
      "171\n",
      "172\n",
      "173\n",
      "174\n",
      "175\n",
      "176\n",
      "177\n",
      "178\n",
      "179\n",
      "180\n",
      "181\n",
      "182\n",
      "183\n",
      "184\n",
      "185\n",
      "186\n",
      "187\n",
      "188\n",
      "189\n",
      "190\n",
      "191\n",
      "192\n",
      "193\n",
      "194\n",
      "195\n",
      "196\n",
      "197\n",
      "198\n",
      "199\n",
      "200\n",
      "201\n",
      "202\n",
      "203\n",
      "204\n",
      "205\n",
      "206\n",
      "207\n",
      "208\n",
      "209\n",
      "210\n",
      "211\n",
      "212\n",
      "213\n",
      "214\n",
      "215\n",
      "216\n",
      "217\n",
      "218\n",
      "219\n",
      "220\n",
      "221\n",
      "222\n",
      "223\n",
      "224\n",
      "225\n",
      "226\n",
      "227\n",
      "228\n",
      "229\n",
      "230\n",
      "231\n",
      "232\n",
      "233\n",
      "234\n",
      "235\n",
      "236\n",
      "237\n",
      "238\n",
      "239\n",
      "240\n",
      "241\n",
      "242\n",
      "243\n",
      "244\n",
      "245\n",
      "246\n",
      "247\n",
      "248\n",
      "249\n",
      "250\n",
      "251\n",
      "252\n",
      "253\n",
      "254\n",
      "255\n",
      "256\n",
      "257\n",
      "258\n",
      "259\n",
      "260\n",
      "261\n",
      "262\n",
      "263\n",
      "264\n",
      "265\n",
      "266\n",
      "267\n",
      "268\n",
      "269\n",
      "270\n",
      "271\n",
      "272\n",
      "273\n",
      "274\n",
      "275\n",
      "276\n",
      "277\n",
      "278\n",
      "279\n",
      "280\n",
      "281\n",
      "282\n",
      "283\n",
      "284\n",
      "285\n",
      "286\n",
      "287\n",
      "288\n",
      "289\n",
      "290\n",
      "291\n",
      "292\n",
      "293\n",
      "294\n",
      "295\n",
      "296\n",
      "297\n",
      "298\n",
      "299\n",
      "300\n",
      "301\n",
      "302\n",
      "303\n",
      "304\n",
      "305\n",
      "306\n",
      "307\n",
      "308\n",
      "309\n",
      "310\n",
      "311\n",
      "312\n",
      "313\n",
      "314\n",
      "315\n",
      "316\n",
      "317\n",
      "318\n",
      "319\n",
      "320\n",
      "321\n",
      "322\n",
      "323\n",
      "324\n",
      "325\n",
      "326\n",
      "327\n",
      "328\n",
      "329\n",
      "330\n",
      "331\n",
      "332\n",
      "333\n",
      "334\n",
      "335\n",
      "336\n",
      "337\n",
      "338\n",
      "339\n",
      "340\n",
      "341\n"
     ]
    }
   ],
   "source": [
    "O1 = np.zeros((N_TESTING_SAMPLES,256,256))\n",
    "O2 = np.zeros((N_TESTING_SAMPLES,256,256))\n",
    "Ground_Truth = np.zeros((N_TESTING_SAMPLES,256,256))\n",
    "Segmentation_from_model_out = np.zeros((N_TESTING_SAMPLES,256,256))\n",
    "Segmentation_from_model_in = np.zeros((N_TESTING_SAMPLES,256,256))\n",
    "Segmentation_from_model = np.zeros((N_TESTING_SAMPLES,256,256))\n",
    "\n",
    "path = \"/tank/data/navchetan/Lars_Annotated_Datasets/Testing_Input\"\n",
    "os.chdir(path)\n",
    "for i in range(N_TESTING_SAMPLES):\n",
    "    if(i%10 == 0):\n",
    "        print(i)\n",
    "    pathr = 'Image'+str(i+1).zfill(5)+'.mat'\n",
    "    x = sio.loadmat(pathr)\n",
    "    O1[i,:,:] = x['U']/255\n",
    "    O2[i,:,:] = x['U']/255\n",
    "    \n",
    "path = \"/tank/data/navchetan/Lars_Annotated_Datasets/Testing_Output_With_Papillary\"\n",
    "os.chdir(path)\n",
    "for i in range(N_TESTING_SAMPLES):\n",
    "    if(i%10 == 0):\n",
    "        print(i)\n",
    "    pathr = 'Segment'+str(i+1).zfill(5)+'.mat'\n",
    "    x = sio.loadmat(pathr)\n",
    "    Ground_Truth[i,:,:] = x['S']\n",
    "    retval2, ground_truth_testing_threshold = cv2.threshold(Ground_Truth[i,:,:],0,255,cv2.THRESH_BINARY)\n",
    "    Ground_Truth[i,:,:] = ground_truth_testing_threshold/255.0\n",
    "    \n",
    "\n",
    "os.chdir(path_results_save)\n",
    "for i in range(N_TESTING_SAMPLES):\n",
    "    if(i%10 == 0):\n",
    "        print(i)\n",
    "    pathr = 'Segment_Output'+str(i+1).zfill(5)+'.mat'\n",
    "    x = sio.loadmat(pathr)\n",
    "    Segmentation_from_model[i,:,:] = x['S']\n",
    "    Segment_model1 = Segmentation_from_model[i,:,:]*255;\n",
    "    retval1, Segment_model_threshold = cv2.threshold(Segment_model1,100,255,cv2.THRESH_BINARY)\n",
    "    Segmentation_from_model[i,:,:] = Segment_model_threshold/255.0\n",
    "    \n",
    "def concat_images(imga, imgb):\n",
    "    \"\"\"\n",
    "    Combines two color image ndarrays side-by-side.\n",
    "    \"\"\"\n",
    "    [ha,wa] = np.shape(imga)\n",
    "    [hb,wb] = np.shape(imgb)\n",
    "    max_height = np.max([ha, hb])\n",
    "    total_width = wa+wb\n",
    "    new_img = np.zeros(shape=(max_height, total_width))\n",
    "    new_img[:ha,:wa]=imga\n",
    "    new_img[:hb,wa:wa+wb]=imgb\n",
    "    return new_img\n",
    "\n",
    "\n",
    "h = 256\n",
    "w = 256\n",
    "img_array = []    \n",
    "for k in range(N_TESTING_SAMPLES):\n",
    "    print(k)\n",
    "    for i in range(h):\n",
    "        for j in range (w):\n",
    "            if Ground_Truth[k,i,j]>0:\n",
    "                O1[k,i,j]=Ground_Truth[k,i,j]\n",
    "            if Segmentation_from_model[k,i,j]>0:\n",
    "                O2[k,i,j]=Segmentation_from_model[k,i,j]\n",
    "    W1 = O1[k,:,:]\n",
    "    W2 = O2[k,:,:]\n",
    "    img = concat_images(W1,W2)\n",
    "    img_array.append(img)\n",
    "    \n",
    "    os.chdir(path_images_save) \n",
    "    pathr = 'Joint_Image'+str(k+1).zfill(5)+'.png'\n",
    "    cv2.imwrite(pathr, img*255) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# import pandas as pd\n",
    "# import scipy.io as sio\n",
    "# import cv2\n",
    "# import numpy as np\n",
    "# from sklearn.metrics import jaccard_similarity_score\n",
    "# from sklearn.metrics import confusion_matrix\n",
    "\n",
    "\n",
    "\n",
    "# name_save_directory = \"LV_Net_Dice_Loss_Inner_with_Papilary_V2\"\n",
    "# results = \"_Results\"\n",
    "# parent_directory = \"/tank/data/navchetan/Lars_Annotated_Datasets/Results/\"\n",
    "# saveFolder = os.path.join(parent_directory,name_save_directory)\n",
    "# name_save_results_directory = name_save_directory+results\n",
    "# path_segment_inner = os.path.join(saveFolder,name_save_results_directory)\n",
    "\n",
    "# name_save_directory = \"LV_Net_Dice_Loss_Outer_V2\"\n",
    "# results = \"_Results\"\n",
    "# parent_directory = \"/tank/data/navchetan/Lars_Annotated_Datasets/Results/\"\n",
    "# saveFolder = os.path.join(parent_directory,name_save_directory)\n",
    "# name_save_results_directory = name_save_directory+results\n",
    "# path_segment_outer = os.path.join(saveFolder,name_save_results_directory)\n",
    "\n",
    "# name_save_directory = \"LV_Net_Dice_Loss_with_papilary_V2\"\n",
    "# results = \"_Results\"\n",
    "# parent_directory = \"/tank/data/navchetan/Lars_Annotated_Datasets/Results/\"\n",
    "# saveFolder = os.path.join(parent_directory,name_save_directory)\n",
    "# name_save_results_directory = name_save_directory+results\n",
    "# path_segment_normal = os.path.join(saveFolder,name_save_results_directory)\n",
    "\n",
    "# name_save_directory = \"LV_Net_Dice_Loss_Outer_Inner_with_Papilary_Final_Post_Processing_V2\"\n",
    "# saving_metrics = 'Metrics_LV_Net_Dice_Loss_Outer_Inner_with_Papilary_Final_Post_Processing_V2.csv'\n",
    "\n",
    "# results = \"_Results\"\n",
    "# images = \"_Joint_Images\"\n",
    "# parent_directory = \"/tank/data/navchetan/Lars_Annotated_Datasets/Results/\"\n",
    "# saveFolder = os.path.join(parent_directory,name_save_directory)\n",
    "# # os.mkdir(saveFolder)\n",
    "\n",
    "# name_save_results_directory = name_save_directory+results\n",
    "# path_results_save = os.path.join(saveFolder,name_save_results_directory)\n",
    "# # os.mkdir(path_results_save)\n",
    "\n",
    "# name_save_images_directory = name_save_directory+images\n",
    "# path_images_save = os.path.join(saveFolder,name_save_images_directory)\n",
    "# # os.mkdir(path_images_save)\n",
    "\n",
    "\n",
    "# cols = ['sensitivity','specificity','accuracy','dice_score','Jaccard']\n",
    "# df = pd.DataFrame(columns=cols)\n",
    "# ratio=['Ratio']\n",
    "# dfr=pd.DataFrame(columns=ratio)\n",
    "# path_testing_ground_truth =\"/tank/data/navchetan/Lars_Annotated_Datasets/Testing_Output_With_Papillary\"\n",
    "\n",
    "# N_TESTING_SAMPLES = 342\n",
    "# print('Loading Testing Data for computation of Jaccard Index')\n",
    "# sensitivity_t = 0\n",
    "# specificity_t = 0\n",
    "# accuracy_t = 0\n",
    "# dice_score_t = 0\n",
    "# Jaccard_t = 0\n",
    "# countoutin = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in range(N_TESTING_SAMPLES):\n",
    "#     if(i%10 == 0):\n",
    "#         print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# i=260"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#     import matplotlib.pyplot as plt\n",
    "# import os\n",
    "# import matplotlib.pyplot as plt\n",
    "#     os.chdir(path_segment_outer)    \n",
    "#     pathr = 'Segment_Output'+str(i+1).zfill(5)+'.mat'\n",
    "#     x = sio.loadmat(pathr)\n",
    "#     Segment_model = x['S']\n",
    "#     Segment_model1 = Segment_model*255;\n",
    "#     retval1, Segment_model_threshold = cv2.threshold(Segment_model1,100,255,cv2.THRESH_BINARY)\n",
    "#     Segment_model_threshold_out = Segment_model_threshold/255.0\n",
    "#     plt.imshow(Segment_model_threshold_out, cmap=\"gray\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#     os.chdir(path_segment_inner)    \n",
    "#     pathr = 'Segment_Output'+str(i+1).zfill(5)+'.mat'\n",
    "#     x = sio.loadmat(pathr)\n",
    "#     Segment_model = x['S']\n",
    "#     Segment_model1 = Segment_model*255;\n",
    "#     retval1, Segment_model_threshold = cv2.threshold(Segment_model1,100,255,cv2.THRESH_BINARY)\n",
    "#     Segment_model_threshold_in = Segment_model_threshold/255.0\n",
    "#     plt.imshow(Segment_model_threshold_in, cmap=\"gray\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#     Segment_model_threshold1=Segment_model_threshold_out-Segment_model_threshold_in\n",
    "    \n",
    "#     for i in range(256):\n",
    "#         for j in range(256):\n",
    "#             if Segment_model_threshold1[i,j]<0:\n",
    "#                 Segment_model_threshold1[i,j]=0\n",
    "                \n",
    "#     plt.imshow(Segment_model_threshold1, cmap=\"gray\")    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#     os.chdir(path_segment_normal)    \n",
    "#     pathr = 'Segment_Output'+str(i+1).zfill(5)+'.mat'\n",
    "#     x = sio.loadmat(pathr)\n",
    "#     Segment_model = x['S']\n",
    "#     Segment_model1 = Segment_model*255;\n",
    "#     retval1, Segment_model_threshold = cv2.threshold(Segment_model1,100,255,cv2.THRESH_BINARY)\n",
    "#     Segment_outin = Segment_model_threshold/255.0\n",
    "#     plt.imshow(Segment_outin, cmap=\"gray\")        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in range(256):\n",
    "#         for j in range(256):\n",
    "#             if Segment_model_threshold1[i,j]==1 and Segment_outin[i,j]==0:\n",
    "#                 Segment_model_threshold1[i,j]=1\n",
    "#             elif Segment_model_threshold1[i,j]==0 and Segment_outin[i,j]==1:\n",
    "#                 Segment_model_threshold1[i,j]=1\n",
    "#             elif Segment_model_threshold1[i,j]==0 and Segment_outin[i,j]==0:\n",
    "#                 Segment_model_threshold1[i,j]=0\n",
    "# kernel=cv2.getStructuringElement(cv2.MORPH_ELLIPSE,(7,7))            \n",
    "# Segment_model_threshold1= cv2.morphologyEx(Segment_model_threshold1, cv2.MORPH_CLOSE, kernel)\n",
    "# Segment_model_threshold1 = cv2.morphologyEx(Segment_model_threshold1, cv2.MORPH_OPEN, kernel)\n",
    "# Segment_model_threshold1= cv2.morphologyEx(Segment_model_threshold1, cv2.MORPH_CLOSE, kernel)\n",
    "# Segment_model_threshold1 = cv2.morphologyEx(Segment_model_threshold1, cv2.MORPH_OPEN, kernel)    \n",
    "    \n",
    "# plt.imshow(Segment_model_threshold1, cmap=\"gray\")     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#     os.chdir(path_results_save)\n",
    "#     S = Segment_model_threshold1\n",
    "#     countoutin = countoutin + 1\n",
    "#     fsave = 'Segment_Output'+str(countoutin).zfill(5)+'.mat'\n",
    "#     sio.savemat(fsave, {'S':S})\n",
    "            \n",
    "#     os.chdir(path_testing_ground_truth)\n",
    "#     path_t = 'Segment'+str(i+1).zfill(5)+'.mat'\n",
    "#     y = sio.loadmat(path_t)\n",
    "#     ground_truth_testing  = y['S']\n",
    "#     ground_truth1 = ground_truth_testing*255;\n",
    "#     retval2, ground_truth_testing_threshold = cv2.threshold(ground_truth1,0,255,cv2.THRESH_BINARY)\n",
    "#     ground_truth_testing_threshold1 = ground_truth_testing_threshold/255.0\n",
    "    \n",
    "#     mcm = confusion_matrix(np.ndarray.flatten(Segment_model_threshold1),np.ndarray.flatten(ground_truth_testing_threshold1))\n",
    "#     tn = mcm[0, 0]\n",
    "#     fp = mcm[0, 1]\n",
    "#     fn = mcm[1, 0]\n",
    "#     tp = mcm[1, 1]\n",
    "    \n",
    "#     sensitivity = tp / (tp + fn)\n",
    "#     specificity = tn / (tn + fp)\n",
    "#     accuracy = (tp + tn) / (tp + tn + fn + fp)\n",
    "#     dice_score = 2*tp / (2*tp + fp + fn)\n",
    "#     Jaccard = dice_score / (2-dice_score)\n",
    "    \n",
    "#     sensitivity_t = sensitivity_t + sensitivity\n",
    "#     specificity_t = specificity_t + specificity\n",
    "#     accuracy_t = accuracy_t + accuracy\n",
    "#     dice_score_t = dice_score_t + dice_score\n",
    "#     Jaccard_t = Jaccard_t + Jaccard\n",
    "    \n",
    "    \n",
    "#     df = df.append(pd.Series([sensitivity,specificity,accuracy,dice_score,Jaccard],index=df.columns), ignore_index=True)\n",
    "\n",
    "# os.chdir(saveFolder)\n",
    "# df.to_csv(saving_metrics,index=False)\n",
    "# #dfr.to_csv('Ratio.csv')\n",
    "# print(sensitivity_t/N_TESTING_SAMPLES)\n",
    "# print(specificity_t/N_TESTING_SAMPLES)\n",
    "# print(dice_score_t/N_TESTING_SAMPLES)\n",
    "# print(accuracy_t/N_TESTING_SAMPLES)\n",
    "# print(Jaccard_t/N_TESTING_SAMPLES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
